{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.003144860119242613,
  "eval_steps": 500,
  "global_step": 60,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 5.2414335320710214e-05,
      "grad_norm": 0.5552601218223572,
      "learning_rate": 4e-05,
      "loss": 1.6498,
      "step": 1
    },
    {
      "epoch": 0.00010482867064142043,
      "grad_norm": 0.6701803803443909,
      "learning_rate": 8e-05,
      "loss": 1.8747,
      "step": 2
    },
    {
      "epoch": 0.00015724300596213064,
      "grad_norm": 0.6510002613067627,
      "learning_rate": 0.00012,
      "loss": 1.9036,
      "step": 3
    },
    {
      "epoch": 0.00020965734128284086,
      "grad_norm": 0.6890547871589661,
      "learning_rate": 0.00016,
      "loss": 1.9792,
      "step": 4
    },
    {
      "epoch": 0.0002620716766035511,
      "grad_norm": 0.5165667533874512,
      "learning_rate": 0.0002,
      "loss": 1.9309,
      "step": 5
    },
    {
      "epoch": 0.00031448601192426127,
      "grad_norm": 0.7358901500701904,
      "learning_rate": 0.00019636363636363636,
      "loss": 1.7613,
      "step": 6
    },
    {
      "epoch": 0.0003669003472449715,
      "grad_norm": 0.5332958698272705,
      "learning_rate": 0.00019272727272727274,
      "loss": 1.5812,
      "step": 7
    },
    {
      "epoch": 0.0004193146825656817,
      "grad_norm": 0.7291893362998962,
      "learning_rate": 0.0001890909090909091,
      "loss": 1.5799,
      "step": 8
    },
    {
      "epoch": 0.0004717290178863919,
      "grad_norm": 0.5890177488327026,
      "learning_rate": 0.00018545454545454545,
      "loss": 1.3288,
      "step": 9
    },
    {
      "epoch": 0.0005241433532071022,
      "grad_norm": 0.5948783755302429,
      "learning_rate": 0.00018181818181818183,
      "loss": 1.6323,
      "step": 10
    },
    {
      "epoch": 0.0005765576885278123,
      "grad_norm": 0.6197741031646729,
      "learning_rate": 0.0001781818181818182,
      "loss": 1.4441,
      "step": 11
    },
    {
      "epoch": 0.0006289720238485225,
      "grad_norm": 0.5076972246170044,
      "learning_rate": 0.00017454545454545454,
      "loss": 1.4797,
      "step": 12
    },
    {
      "epoch": 0.0006813863591692327,
      "grad_norm": 0.560221791267395,
      "learning_rate": 0.0001709090909090909,
      "loss": 1.3484,
      "step": 13
    },
    {
      "epoch": 0.000733800694489943,
      "grad_norm": 0.4574580490589142,
      "learning_rate": 0.00016727272727272728,
      "loss": 1.3285,
      "step": 14
    },
    {
      "epoch": 0.0007862150298106532,
      "grad_norm": 0.7150502800941467,
      "learning_rate": 0.00016363636363636366,
      "loss": 1.415,
      "step": 15
    },
    {
      "epoch": 0.0008386293651313634,
      "grad_norm": 0.43473419547080994,
      "learning_rate": 0.00016,
      "loss": 1.6182,
      "step": 16
    },
    {
      "epoch": 0.0008910437004520736,
      "grad_norm": 0.4427371323108673,
      "learning_rate": 0.00015636363636363637,
      "loss": 1.3621,
      "step": 17
    },
    {
      "epoch": 0.0009434580357727838,
      "grad_norm": 0.6238763332366943,
      "learning_rate": 0.00015272727272727275,
      "loss": 1.5979,
      "step": 18
    },
    {
      "epoch": 0.0009958723710934941,
      "grad_norm": 0.5442692637443542,
      "learning_rate": 0.0001490909090909091,
      "loss": 1.3563,
      "step": 19
    },
    {
      "epoch": 0.0010482867064142043,
      "grad_norm": 0.4982586205005646,
      "learning_rate": 0.00014545454545454546,
      "loss": 1.6371,
      "step": 20
    },
    {
      "epoch": 0.0011007010417349145,
      "grad_norm": 0.4479053318500519,
      "learning_rate": 0.00014181818181818184,
      "loss": 1.543,
      "step": 21
    },
    {
      "epoch": 0.0011531153770556247,
      "grad_norm": 0.4251404106616974,
      "learning_rate": 0.0001381818181818182,
      "loss": 1.279,
      "step": 22
    },
    {
      "epoch": 0.001205529712376335,
      "grad_norm": 0.4622485041618347,
      "learning_rate": 0.00013454545454545455,
      "loss": 1.4169,
      "step": 23
    },
    {
      "epoch": 0.001257944047697045,
      "grad_norm": 0.38942065834999084,
      "learning_rate": 0.00013090909090909093,
      "loss": 1.2348,
      "step": 24
    },
    {
      "epoch": 0.0013103583830177553,
      "grad_norm": 0.5501433610916138,
      "learning_rate": 0.00012727272727272728,
      "loss": 1.6151,
      "step": 25
    },
    {
      "epoch": 0.0013627727183384655,
      "grad_norm": 0.48808425664901733,
      "learning_rate": 0.00012363636363636364,
      "loss": 1.8561,
      "step": 26
    },
    {
      "epoch": 0.0014151870536591759,
      "grad_norm": 0.5510837435722351,
      "learning_rate": 0.00012,
      "loss": 1.5146,
      "step": 27
    },
    {
      "epoch": 0.001467601388979886,
      "grad_norm": 0.4811727702617645,
      "learning_rate": 0.00011636363636363636,
      "loss": 1.3686,
      "step": 28
    },
    {
      "epoch": 0.0015200157243005963,
      "grad_norm": 0.453205943107605,
      "learning_rate": 0.00011272727272727272,
      "loss": 1.5784,
      "step": 29
    },
    {
      "epoch": 0.0015724300596213065,
      "grad_norm": 0.4267280697822571,
      "learning_rate": 0.00010909090909090909,
      "loss": 1.7192,
      "step": 30
    },
    {
      "epoch": 0.0016248443949420167,
      "grad_norm": 0.42362716794013977,
      "learning_rate": 0.00010545454545454545,
      "loss": 1.6624,
      "step": 31
    },
    {
      "epoch": 0.0016772587302627269,
      "grad_norm": 0.5574385523796082,
      "learning_rate": 0.00010181818181818181,
      "loss": 1.5433,
      "step": 32
    },
    {
      "epoch": 0.001729673065583437,
      "grad_norm": 0.5070927143096924,
      "learning_rate": 9.818181818181818e-05,
      "loss": 1.4663,
      "step": 33
    },
    {
      "epoch": 0.0017820874009041472,
      "grad_norm": 0.3879343867301941,
      "learning_rate": 9.454545454545455e-05,
      "loss": 1.4429,
      "step": 34
    },
    {
      "epoch": 0.0018345017362248574,
      "grad_norm": 0.6384862661361694,
      "learning_rate": 9.090909090909092e-05,
      "loss": 1.3976,
      "step": 35
    },
    {
      "epoch": 0.0018869160715455676,
      "grad_norm": 0.39456096291542053,
      "learning_rate": 8.727272727272727e-05,
      "loss": 1.3665,
      "step": 36
    },
    {
      "epoch": 0.0019393304068662778,
      "grad_norm": 0.4019273519515991,
      "learning_rate": 8.363636363636364e-05,
      "loss": 1.2707,
      "step": 37
    },
    {
      "epoch": 0.0019917447421869882,
      "grad_norm": 0.5763960480690002,
      "learning_rate": 8e-05,
      "loss": 1.4314,
      "step": 38
    },
    {
      "epoch": 0.0020441590775076984,
      "grad_norm": 0.6771582365036011,
      "learning_rate": 7.636363636363637e-05,
      "loss": 1.7074,
      "step": 39
    },
    {
      "epoch": 0.0020965734128284086,
      "grad_norm": 0.5152075886726379,
      "learning_rate": 7.272727272727273e-05,
      "loss": 1.5666,
      "step": 40
    },
    {
      "epoch": 0.002148987748149119,
      "grad_norm": 0.528792142868042,
      "learning_rate": 6.90909090909091e-05,
      "loss": 1.656,
      "step": 41
    },
    {
      "epoch": 0.002201402083469829,
      "grad_norm": 0.5524833798408508,
      "learning_rate": 6.545454545454546e-05,
      "loss": 1.42,
      "step": 42
    },
    {
      "epoch": 0.002253816418790539,
      "grad_norm": 0.3538052439689636,
      "learning_rate": 6.181818181818182e-05,
      "loss": 1.3455,
      "step": 43
    },
    {
      "epoch": 0.0023062307541112494,
      "grad_norm": 0.5318982005119324,
      "learning_rate": 5.818181818181818e-05,
      "loss": 1.6161,
      "step": 44
    },
    {
      "epoch": 0.0023586450894319596,
      "grad_norm": 0.4989137351512909,
      "learning_rate": 5.4545454545454546e-05,
      "loss": 1.7867,
      "step": 45
    },
    {
      "epoch": 0.00241105942475267,
      "grad_norm": 0.5393503308296204,
      "learning_rate": 5.090909090909091e-05,
      "loss": 1.3944,
      "step": 46
    },
    {
      "epoch": 0.00246347376007338,
      "grad_norm": 0.39617782831192017,
      "learning_rate": 4.7272727272727275e-05,
      "loss": 1.2363,
      "step": 47
    },
    {
      "epoch": 0.00251588809539409,
      "grad_norm": 0.5258579254150391,
      "learning_rate": 4.3636363636363636e-05,
      "loss": 1.4866,
      "step": 48
    },
    {
      "epoch": 0.0025683024307148004,
      "grad_norm": 0.5093401074409485,
      "learning_rate": 4e-05,
      "loss": 1.4996,
      "step": 49
    },
    {
      "epoch": 0.0026207167660355106,
      "grad_norm": 0.48273178935050964,
      "learning_rate": 3.6363636363636364e-05,
      "loss": 1.6643,
      "step": 50
    },
    {
      "epoch": 0.0026731311013562208,
      "grad_norm": 0.46775949001312256,
      "learning_rate": 3.272727272727273e-05,
      "loss": 1.9088,
      "step": 51
    },
    {
      "epoch": 0.002725545436676931,
      "grad_norm": 0.5355923175811768,
      "learning_rate": 2.909090909090909e-05,
      "loss": 1.4857,
      "step": 52
    },
    {
      "epoch": 0.002777959771997641,
      "grad_norm": 0.41552427411079407,
      "learning_rate": 2.5454545454545454e-05,
      "loss": 1.3526,
      "step": 53
    },
    {
      "epoch": 0.0028303741073183518,
      "grad_norm": 0.6492355465888977,
      "learning_rate": 2.1818181818181818e-05,
      "loss": 1.2892,
      "step": 54
    },
    {
      "epoch": 0.002882788442639062,
      "grad_norm": 0.5098933577537537,
      "learning_rate": 1.8181818181818182e-05,
      "loss": 1.4417,
      "step": 55
    },
    {
      "epoch": 0.002935202777959772,
      "grad_norm": 0.5813028216362,
      "learning_rate": 1.4545454545454545e-05,
      "loss": 1.4405,
      "step": 56
    },
    {
      "epoch": 0.0029876171132804824,
      "grad_norm": 0.6192118525505066,
      "learning_rate": 1.0909090909090909e-05,
      "loss": 1.525,
      "step": 57
    },
    {
      "epoch": 0.0030400314486011925,
      "grad_norm": 0.4532555937767029,
      "learning_rate": 7.272727272727272e-06,
      "loss": 1.3743,
      "step": 58
    },
    {
      "epoch": 0.0030924457839219027,
      "grad_norm": 0.5129924416542053,
      "learning_rate": 3.636363636363636e-06,
      "loss": 1.4394,
      "step": 59
    },
    {
      "epoch": 0.003144860119242613,
      "grad_norm": 0.6032310724258423,
      "learning_rate": 0.0,
      "loss": 1.2487,
      "step": 60
    }
  ],
  "logging_steps": 1,
  "max_steps": 60,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 5434563669663744.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
